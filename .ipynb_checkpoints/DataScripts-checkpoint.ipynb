{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these are queries from different notebooks with different datas. There could be no relation\n",
    "#between queries inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To import a dataset from csv\n",
    "data=pd.read_csv(\"google.csv\")\n",
    "\n",
    "#To import from excel\n",
    "data=pd.read_excel('r',\"file_name.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To choose  specific part of the data\n",
    "data=data[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#running bunch of queries \n",
    "data.head()\n",
    "data.tail()\n",
    "data.nunique()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some times data does not have column labels. We define labels for columns\n",
    "column_names = [\"project_name\", \"build_numbers\", \"failure_rate\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choosing specific columns of data\n",
    "df=data[['column_A', 'column_C', 'column_G', 'column_B']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an empty dataframe\n",
    "new_dataFrame=pd.DataFrame(columns=['A','B','C','D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bunch of queries on columns od dataFrame\n",
    "df=data[data.test_name == 'win']\n",
    "df=data[data.Size!='LARGE']\n",
    "df=data[data.Language=='CC']\n",
    "\n",
    "\n",
    "data.test_name.nunique()\n",
    "data.test_name.unique()\n",
    "data.test_name.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sometimes a column is a string cosisting of multiple values seperating by a character e.g. ;\n",
    "# We first see some examples of working with them and then try to seperate them in different rows\n",
    "# for example, there is a table with these values\n",
    "#       column_A\n",
    "#A   '[aa; bb'\n",
    "#B   '[dd; ee]'\n",
    "#We want to flatten it and make it \n",
    "#A    aa\n",
    "#A    bb\n",
    "#B    dd\n",
    "#B    ee\n",
    "# We first need to remove [ and ]. We then flatten it using explode method\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing '[' and ']' characters\n",
    "df=df.assign( column_name=df.column_name.str.replace('[', \"\"))\n",
    "df=df.assign( column_name=df.column_name.str.replace(']', \"\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploding them into different rows \n",
    "df=df.assign( column_name=df.column_name.str.split(\";\")).explode('column_name')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sometimes there is a need to itterate over column of a dataframe. to preform this, we do loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is part of another program. the important part is the loop over the rows of the dataframe\n",
    "#The original program could easily  be implemented using groupby. This way is just for learning\n",
    "outcome=[]\n",
    "flag=True\n",
    "current_build=5\n",
    "for index, row in data.iterrows():\n",
    "\n",
    "    if(current_build!=row['build']):\n",
    "        outcome.append(flag)\n",
    "        flag=True\n",
    "        current_build=row['build']\n",
    "    if(row['verdict']==True):\n",
    "        pass\n",
    "    else:\n",
    "        flag=False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Most of the times we need to group elements in a dataframe based on one or multiple columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can group with any column we want\n",
    "group=data.groupby(['column_A'])\n",
    "group=data.groupby(['column_A','column_B'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sometimes we need to more complex function on each group. In this situation we use apply function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=group.apply(lambda x: x['UP_LMC_Content'].nunique())\n",
    "print(df.sort_values(ascending=True))\n",
    "df2=group.apply(lambda x: x['Start'].min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sometimes we have to itterate over elements of group object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(grouped_data):\n",
    "    rows=[]\n",
    "    new_df = pd.DataFrame(columns=['A', 'B', 'C','D'])\n",
    "    for element in grouped_data:\n",
    "        print(len(grouped_data))\n",
    "        A=element[0][0]\n",
    "        B=element[0][1]\n",
    "        C=element[1]['C'].min()\n",
    "        D=(bool(set(['SUCCESS', 'PASSED']) & set(element[1]['D'].values)))\n",
    "        new_row={'A':A, 'B':B, 'C':C, 'D':D}\n",
    "        rows.append(new_row)\n",
    "       \n",
    "    new_df = pd.DataFrame(rows)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Itterate over elements and apply function could be slow. They do not use the whole cpu cores.\n",
    "#to speed up the process, we need to parlelize some parts of the code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import time\n",
    "\n",
    "def parallelize_dataframe(grouped_data, func, n_cores):\n",
    "    grouped_data_split=[]\n",
    "    grouped_data_split=np.array_split(grouped_data, n_cores)\n",
    "\n",
    "   \n",
    "    start = time.time()\n",
    "    pool = Pool(n_cores)\n",
    "    df = pd.concat(pool.map(func, grouped_data_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    end = time.time()\n",
    "    print(f\"Runtime of the program is {end - start}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to call parallelize_dataframe,  we cannot directly use create_table function in notebook. Instead we will get \n",
    "#an endless loop. Instead we have to store the function in a pythin file and import and then we can use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stored_file_function\n",
    "x=parallelize_dataframe(group, stored_file_function.create_table, 3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
